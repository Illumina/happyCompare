<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Extracting metrics • happyCompare</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">happyCompare</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/extracting_metrics.html">Extracting metrics</a>
    </li>
    <li>
      <a href="../articles/quick_start.html">Quick start guide</a>
    </li>
    <li>
      <a href="../articles/simulations.html">Calibrating HDIs with simulated data</a>
    </li>
    <li>
      <a href="../articles/stratified_counts.html">Analysing stratified counts</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Extracting metrics</h1>
                        <h4 class="author">Mar Gonzalez-Porta</h4>
            
            <h4 class="date">2017-09-28</h4>
          </div>

    
    
<div class="contents">
<p>In this vignette we will illustrate how to access hap.py results once we have created a <code>happy_compare</code> object. Also, we will cover how to complement them with custom metrics, just by adding an additional <code>build_metrics</code> column to our samplesheet.</p>
<div id="set-up" class="section level2">
<h2 class="hasAnchor">
<a href="#set-up" class="anchor"></a>Set up</h2>
<p>Let’s load our NovaSeq dataset with PCR-Free vs. Nano builds for NA12878, using a samplesheet that includes custom metrics (see <code>vignettes/pcrfree_vs_nano.csv</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># do not run</span>
samplesheet_path &lt;-<span class="st"> "vignettes/pcrfree_vs_nano.csv"</span>
happy_compare &lt;-<span class="st"> </span><span class="kw"><a href="../reference/read_samplesheet.html">read_samplesheet</a></span>(samplesheet_path, <span class="dt">lazy =</span> <span class="ot">TRUE</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># given the size of the dataset, load from Rds object instead</span>
happy_compare &lt;-<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">"pcrfree_vs_nano.Rds"</span>)</code></pre></div>
<p>We can have a look at the contents of the resulting <code>happy_compare</code> object to identify which elements are available for querying:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(happy_compare)
## [1] "samplesheet"   "happy_results" "build_metrics" "ids"</code></pre></div>
</div>
<div id="accessing-hap-py-results" class="section level2">
<h2 class="hasAnchor">
<a href="#accessing-hap-py-results" class="anchor"></a>Accessing hap.py results</h2>
<p>Since our demo dataset includes results from two different library preparation workflows, we can evaluate if there are any differences in variant calling performance across groups. For that, we will need to access hap.py results. In particular, we are interested in ROC metrics, as ROC curves offer a convenient way of visualising accuracy across multiple classification methods (in our case True Positive vs. False Positive calls in PCR-Free vs. Nano builds).</p>
<p>Let’s extract ROC metrics for PASS SNVs and INDELs in our <code>happy_compare</code> dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">roc_snvs &lt;-<span class="st"> </span><span class="kw"><a href="../reference/extract_metrics.html">extract_metrics</a></span>(happy_compare, <span class="dt">table =</span> <span class="st">"pr.snp.pass"</span>)
roc_indels &lt;-<span class="st"> </span><span class="kw"><a href="../reference/extract_metrics.html">extract_metrics</a></span>(happy_compare, <span class="dt">table =</span> <span class="st">"pr.indel.pass"</span>)</code></pre></div>
<p>Then visualise them with the pre-defined function <code><a href="../reference/hc_plot_roc.html">hc_plot_roc()</a></code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/hc_plot_roc.html">hc_plot_roc</a></span>(<span class="dt">happy_roc =</span> roc_snvs, <span class="dt">type =</span> <span class="st">"SNP"</span>, <span class="dt">filter =</span> <span class="st">"PASS"</span>)
p2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/hc_plot_roc.html">hc_plot_roc</a></span>(<span class="dt">happy_roc =</span> roc_indels, <span class="dt">type =</span> <span class="st">"INDEL"</span>, <span class="dt">filter =</span> <span class="st">"PASS"</span>)
gridExtra::<span class="kw">grid.arrange</span>(p1, p2, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="extracting_metrics_files/figure-html/unnamed-chunk-6-1.png" width="672"></p>
<p>From the difference in scales between the two plots, we can see that performance is higher for SNPs compared to INDELs, regardless of prep method. In addition, the differences between PCR-Free and Nano are most accentuated in INDELs, with a wider spread in precision across Nano builds.</p>
</div>
<div id="linking-hap-py-results-with-custom-metrics" class="section level2">
<h2 class="hasAnchor">
<a href="#linking-hap-py-results-with-custom-metrics" class="anchor"></a>Linking hap.py results with custom metrics</h2>
<p>Often we have additional information about our samples besides the results generated with hap.py, e.g. metadata, BAM/VCF metrics, etc. It is easy to add these custom metrics to our <code>happy_compare</code> object, we just need to provide a <code>build_metrics</code> column to our samplesheet that points to relevant csv files (see e.g. <code>vignettes/pcrfree_vs_nano.csv</code>). Here we will refer to custom metrics as build metrics, since they are typically metrics calculated on the outputs of the analysis pipeline (BAMs, VCFs), i.e. after “building” the alignments.</p>
<p>For example, the build metrics csv for our first sample contains the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">happy_compare$build_metrics[[<span class="dv">1</span>]] %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">t</span>() %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>(<span class="dt">n =</span> <span class="dv">15</span>)
##                          [,1]                                                                                            
## filename                 "/illumina/build/stripes/happyTestData/pcrfree_vs_nano/build_metrics/NA12878-I30_S1.summary.csv"
## sample_id                "NA12878-I30"                                                                                   
## sample_name              "NA12878-I30"                                                                                   
## run_folder               "/data/scratch/RunFolder"                                                                       
## reference_genome         "Homo"                                                                                          
## paired_end               "True"                                                                                          
## metrics_version          "1.0.9.1"                                                                                       
## metrics_deliverable      "Default"                                                                                       
## callability              "95.3"                                                                                          
## contamination            "0.54"                                                                                          
## autosome_mean_coverage   "49.95"                                                                                         
## autosome_coverage_at_1x  "99.55"                                                                                         
## autosome_coverage_at_10x "98.81"                                                                                         
## autosome_coverage_at_15x "98.52"                                                                                         
## autosome_callability     "96.32"</code></pre></div>
<p>A more convenient way to access build metrics is to use the <code><a href="../reference/extract_metrics.html">extract_metrics()</a></code> function, as we did for hap.py results. This adds a unique identifier to each sample in our dataset, making it easier to combine data downstream. As an example, let’s explore further the spread in INDEL precision identified in the ROC curves above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># link build metrics to hap.py results</span>
summary &lt;-<span class="st"> </span><span class="kw"><a href="../reference/extract_metrics.html">extract_metrics</a></span>(happy_compare, <span class="dt">table =</span> <span class="st">"summary"</span>)
build_metrics &lt;-<span class="st"> </span><span class="kw"><a href="../reference/extract_metrics.html">extract_metrics</a></span>(happy_compare, <span class="dt">table =</span> <span class="st">"build.metrics"</span>)
merged_df &lt;-<span class="st"> </span>summary %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="co"># focus on PASS INDEL for now</span>
<span class="st">  </span><span class="kw">filter</span>(Type ==<span class="st"> "INDEL"</span>, Filter ==<span class="st"> "PASS"</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="co"># focus on precision</span>
<span class="st">  </span><span class="kw">select</span>(happy_prefix, METRIC.Precision) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">inner_join</span>(build_metrics)
## Joining, by = "happy_prefix"</code></pre></div>
<p>Since we have access to BAM metrics, we can investigate if there is any coverage bias in our dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">merged_df %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mean_coverage, <span class="dt">y =</span> METRIC.Precision, <span class="dt">group =</span> Group.Id)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> Group.Id)) +
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">"lm"</span>, <span class="kw">aes</span>(<span class="dt">color =</span> Group.Id, <span class="dt">fill =</span> Group.Id), 
              <span class="dt">formula =</span> y ~<span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">2</span>), <span class="dt">lwd =</span> <span class="fl">0.25</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">"INDEL_precision"</span>)</code></pre></div>
<p><img src="extracting_metrics_files/figure-html/unnamed-chunk-9-1.png" width="576"></p>
<p>As expected, increasing coverage leads to higher INDEL precision. Importantly, precision gains from increased coverage are not equivalent across prep methods: whilst we have reached saturation levels for PCR-Free, we can mitigate the gaps in precision in Nano by sequencing at higher depth.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#set-up">Set up</a></li>
      <li><a href="#accessing-hap-py-results">Accessing hap.py results</a></li>
      <li><a href="#linking-hap-py-results-with-custom-metrics">Linking hap.py results with custom metrics</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Mar Gonzalez-Porta, Ben Moore.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
