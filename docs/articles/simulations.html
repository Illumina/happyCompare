<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Calibrating HDIs with simulated data • happyCompare</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">happyCompare</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/simulations.html">Calibrating HDIs with simulated data</a>
    </li>
    <li>
      <a href="../articles/stratified_counts.html">Analysing stratified counts</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Calibrating HDIs with simulated data</h1>
                        <h4 class="author">Mar Gonzalez-Porta</h4>
            
            <h4 class="date">2017-07-06</h4>
          </div>

    
    
<div class="contents">
<p>One way to evaluate the accuracy of our highest density intervals (HDIs) is to rely on simulated data. Under that scenario, we know what the true success rate is, and we can measure how often that value is captured by our HDI estimates. However, we do not want to rely on a simulation approach that is based solely on the model that we have used for estimation, since it might not be fully representative of real data.</p>
<div id="simulation-strategy" class="section level2">
<h2 class="hasAnchor">
<a href="#simulation-strategy" class="anchor"></a>Simulation strategy</h2>
<p>Let us take recall measurements across <span class="math inline">\(r\)</span> replicates as an example. For a subset with <span class="math inline">\(n\)</span> total variants we can classify each variant into one of these 3 groups:</p>
<ol style="list-style-type: decimal">
<li>the variant is consistently called across all of the replicates (always seen)</li>
<li>the variant is only called in a subset of the replicates (sometimes seen)</li>
<li>the variant is never called (never seen)</li>
</ol>
<p>We can then define our true recall <span class="math inline">\(q\)</span> as follows:</p>
<p><span class="math inline">\(q = (n*q_1*x_1 + n*q_2*x_2 + n*q_3*x_3) / n\)</span></p>
<p>where <span class="math inline">\(n\)</span>: total number of variants in the subset; <span class="math inline">\(q_1\)</span>: probability of having variants in group 1; <span class="math inline">\(x_1\)</span>: recall in group 1 (will always be 1); <span class="math inline">\(q_2\)</span>: probability of having variants in group 2; <span class="math inline">\(x_2\)</span>: recall in group 2 (variable); <span class="math inline">\(q_3\)</span>: probability of having variants in group 3; <span class="math inline">\(x_3\)</span>: recall in group 3 (will always be 0).</p>
<p>From these parameters, we can simulate true positive counts in one sample by drawing from a multinomial distribution that attributes each of the <span class="math inline">\(n\)</span> variants into one of the groups using the defined probabilities <span class="math inline">\(\{q_1, q_2, q_3\}\)</span>. We can next simulate replicates from this sample by performing random binomial draws from each group with recalls <span class="math inline">\(\{x_1, x_2, x_3\}\)</span>.</p>
<p>Note that the number of true positives for groups 1 and 3 will be fixed across replicates by definition, but we can still take advantage of variants in the group 2 to simulate replicate variability. As a result of this variability, our observed recall will differ slightly from the theoretical expectation <span class="math inline">\(q\)</span>.</p>
</div>
<div id="generating-the-simulated-dataset" class="section level2">
<h2 class="hasAnchor">
<a href="#generating-the-simulated-dataset" class="anchor"></a>Generating the simulated dataset</h2>
<p><code>happyCompare</code> includes an R script to produce simulated data using the method described above. After simulating true positive counts, the script will call <code><a href="http://www.rdocumentation.org/packages/happyCompare/topics/estimate_hdi">happyCompare::estimate_hdi()</a></code> to estimate 95% HDIs, and will report the full output in the specified location. For example, the dataset from the present vignette was generated with the following parameters:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ot">output=</span><span class="st">"r5.params_1.csv"</span>
<span class="kw">Rscript</span> --vanilla inst/R/simulate_data.R --q1 0.1 --q2 0.8 --q3 0.1 \
  --x_from 0 --x_to 1 --x_by 0.1 --r 5 --n_from 1 --n_to 1000 --n_by 1 \
  --output_csv <span class="ot">$output</span> --sample_size 100000</code></pre></div>
<p>Note that for the purpose of the script <span class="math inline">\(x_2\)</span> has been renamed to <span class="math inline">\(x\)</span> since it’s the only value of <span class="math inline">\(\{x_1, x_2, x_3\}\)</span> that varies.</p>
</div>
<div id="simulation-results" class="section level2">
<h2 class="hasAnchor">
<a href="#simulation-results" class="anchor"></a>Simulation results</h2>
<p>Let’s first import the simulated dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_data &lt;-<span class="st"> </span>readr::<span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">"~/workspace/git/happyTestData/simulations/r5.params_1.csv"</span>)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   sample_id = col_character(),
##   subset_id = col_character(),
##   expected_p = col_double(),
##   replicate_id = col_character(),
##   successes = col_double(),
##   totals = col_integer(),
##   mu = col_double(),
##   sigma = col_double(),
##   alpha0 = col_double(),
##   beta0 = col_double(),
##   alpha1 = col_double(),
##   beta1 = col_double(),
##   lower = col_double(),
##   observed_p = col_double(),
##   estimated_p = col_double(),
##   upper = col_double(),
##   hdi_range = col_double()
## )</code></pre>
<p>And inspect the distribution of observed recall (gray) in the context of our expectations about theoretical recall (black):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() +
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sim_data$observed_p), <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">lwd =</span> <span class="dv">1</span>, <span class="dt">bins =</span> <span class="dv">1000</span>) +
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sim_data$expected_p, <span class="dt">lwd =</span> <span class="fl">0.5</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">"black"</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">"Observed vs. expected recall"</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">"recall"</span>)</code></pre></div>
<p><img src="simulations_files/figure-html/unnamed-chunk-4-1.png" width="576"></p>
<p>From this plot we can conclude that our simulation strategy has succeeded in introducing replicate variability. We can next move on to evaluate the accuracy of our HDI estimates.</p>
<div id="hdi-estimates-capture-true-and-observed-success-rates" class="section level3">
<h3 class="hasAnchor">
<a href="#hdi-estimates-capture-true-and-observed-success-rates" class="anchor"></a>HDI estimates capture true and observed success rates</h3>
<p>Since we have calculated 95% HDIs, we expect that our HDIs include the true level of recall in at least 95% of the subsets. We can see that this is indeed the case:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_data %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(replicate_id ==<span class="st"> ".aggregate"</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">accurate_hdi =</span> (lower &lt;=<span class="st"> </span>expected_p &amp;<span class="st"> </span>expected_p &lt;=<span class="st"> </span>upper)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">frac_accurate_hdi =</span> <span class="kw">mean</span>(accurate_hdi),
            <span class="dt">N =</span> <span class="kw">n</span>()) %&gt;%<span class="st"> </span>
<span class="st">  </span>knitr::<span class="kw">kable</span>()</code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">frac_accurate_hdi</th>
<th align="right">N</th>
</tr></thead>
<tbody><tr class="odd">
<td align="right">0.9813636</td>
<td align="right">11000</td>
</tr></tbody>
</table>
<p>Given that we have simulated replicates, we can also assess how often our HDIs contain all of the per-replicate observed recalls. Again, we would expect this to be true for 95% of the cases, as failure to do so would suggest that our estimates are too conservative and fail to capture the observed variability. We can see that the results match our expectations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">merge</span>(
  <span class="co"># replicates</span>
  sim_data %&gt;%<span class="st"> </span><span class="kw">filter</span>(replicate_id !=<span class="st"> ".aggregate"</span>) %&gt;%<span class="st"> </span><span class="kw">select</span>(subset_id, observed_p),
  <span class="co"># aggregate</span>
  sim_data %&gt;%<span class="st"> </span><span class="kw">filter</span>(replicate_id ==<span class="st"> ".aggregate"</span>) %&gt;%<span class="st"> </span><span class="kw">select</span>(subset_id, lower, upper),
  <span class="dt">by =</span> <span class="st">"subset_id"</span>
) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">per_subset_accurate_hdi =</span> <span class="kw">ifelse</span>(lower &lt;=<span class="st"> </span>observed_p &amp;<span class="st"> </span>observed_p &lt;=<span class="st"> </span>upper, <span class="ot">TRUE</span>, <span class="ot">FALSE</span>)) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(subset_id) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">accurate_hdi =</span> <span class="kw">all</span>(per_subset_accurate_hdi) ==<span class="st"> </span><span class="ot">TRUE</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">frac_accurate_hdi =</span> <span class="kw">mean</span>(accurate_hdi),
            <span class="dt">N =</span> <span class="kw">n</span>()) %&gt;%<span class="st"> </span>
<span class="st">  </span>knitr::<span class="kw">kable</span>()</code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="right">frac_accurate_hdi</th>
<th align="right">N</th>
</tr></thead>
<tbody><tr class="odd">
<td align="right">0.949</td>
<td align="right">11000</td>
</tr></tbody>
</table>
</div>
<div id="hdi-range-responds-to-subset-size-and-replicate-variability" class="section level3">
<h3 class="hasAnchor">
<a href="#hdi-range-responds-to-subset-size-and-replicate-variability" class="anchor"></a>HDI range responds to subset size and replicate variability</h3>
<p>Finally, we can evaluate whether the width of our HDIs responds as expected to the two variables that we are attempting to model:</p>
<ul>
<li>The number of observations per subset: we expect narrower HDIs as the number of observations increases</li>
<li>Replicate variability: as variability increases, the confidence in our estimates should decrease and the HDIs should become wider</li>
</ul>
<p>We can see that the observed trends match the expected ones:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_data %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(replicate_id ==<span class="st"> ".aggregate"</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> totals, <span class="dt">y =</span> hdi_range)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">"black"</span>, <span class="dt">alpha =</span> <span class="fl">0.1</span>) +
<span class="st">  </span><span class="kw">geom_smooth</span>() +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">"N observations per subset"</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">"HDI range"</span>) +
<span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">"HDI range vs. N observations per subset"</span>)</code></pre></div>
<pre><code>## `geom_smooth()` using method = 'gam'</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-7-1.png" width="576"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sim_data %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(replicate_id ==<span class="st"> ".aggregate"</span>) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">N =</span> totals) %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sigma, <span class="dt">y =</span> hdi_range, <span class="dt">color =</span> N)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>) +
<span class="st">  </span><span class="kw">scale_color_continuous</span>(<span class="dt">trans =</span> <span class="st">"log"</span>, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>, <span class="dv">1000000</span>)) +
<span class="st">  </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">"Per-subset SD"</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">"HDI range"</span>) +
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">"HDI range vs. per-subset variability"</span>)</code></pre></div>
<p><img src="simulations_files/figure-html/unnamed-chunk-8-1.png" width="576"></p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#simulation-strategy">Simulation strategy</a></li>
      <li><a href="#generating-the-simulated-dataset">Generating the simulated dataset</a></li>
      <li><a href="#simulation-results">Simulation results</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Mar Gonzalez-Porta, Ben Moore.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
