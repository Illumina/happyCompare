---
output: github_document
---

```{r include=FALSE}
knitr::opts_chunk$set(cache = FALSE, fig.path = "examples/README-")
```

# happyCompare

happyCompary offers a set of functions to facilitate downstream analysis of variant calling performance outputs from [hap.py](https://github.com/Illumina/hap.py).
It builds on top of [happyR](https://github.com/Illumina/happyR) to support annotation of hap.py results (e.g. grouping) through metadata samplesheets, and provides methods for quick retrieval, statistical analysis and easy reporting of performance metrics.


## Install


Download [zip](https://git.illumina.com/Bioinformatics/happyCompare/archive/master.zip), extract and run:

```{r install, eval=FALSE}
devtools::install_local("path/to/happyCompare-master/")
```

## Usage

```{r message=FALSE, collapse=TRUE}
library("happyCompare")

# loading demo data from a happyCompare samplesheet creates a happy_compare object...
samplesheet_path <- system.file("extdata/samplesheets", "pcrfree_vs_nano.readme.csv", package = "happyCompare")
happy_compare <- read_samplesheet(samplesheet_path, lazy = TRUE)
class(happy_compare)

# ... that contains the following fields:
# - samplesheet: the original samplesheet
# - happy_results: a list of happy_result objects as defined in happyR
# - ids: a vector of build ids
sapply(happy_compare, class)

# hap.py results and samplesheet metadata can be accessed with extract_metrics(),
# leaving them ready for downstream analysis
e <- extract_metrics(happy_compare, table = "summary")
class(e)
```

## Example visualisations

```{r include=FALSE}
library("tidyverse")
library("ggplot2")
theme_set(theme_bw())
```

### Summary of performance metrics

```{r}
# we can easily extract performance metrics and tabulate mean plus/minus SD 
# per group and variant type
extract_metrics(happy_compare, table = "summary") %>% 
  filter(Filter == "PASS") %>% 
  hc_summarise_metrics(df = ., group_cols = c("Group.Id", "Type")) %>% 
  knitr::kable()
```

### Precision-recall curves

```{r message=FALSE, fig.width=5}
# similarly, we can extract roc metrics and plot a precision-recall curve for PASS INDEL
extract_metrics(happy_compare, table = "pr.all") %>% 
  hc_plot_roc(happy_roc = ., type = "INDEL", filter = "PASS")
```

### Stratified counts

```{r fig.height=3}
# finally, we can extract stratified counts and estimate highest density intervals 
# for recall in level 0 subsets...
hdi <- extract_metrics(happy_compare, table = "extended") %>% 
  filter(Subtype == "*", Filter == "PASS", Subset.Level == 0, 
         Subset %in% c("high.at", "high.gc")) %>% 
  estimate_hdi(successes_col = "TRUTH.TP", totals_col = "TRUTH.TOTAL", 
               group_cols = c("Group.Id", "Subset", "Type"), aggregate_only = FALSE)

# ... and generate custom plots with ggplot2
hdi %>% 
  mutate(Subset = factor(Subset, levels = rev(unique(Subset)))) %>% 
  filter(replicate_id == ".aggregate") %>% 
  ggplot(aes(x = estimated_p, y = Subset, group = Subset)) +
    geom_point(aes(color = Group.Id), size = 2) +
    geom_errorbarh(aes(xmin = lower, xmax = upper, color = Group.Id), height = 0.4) +
    facet_grid(. ~ Type) +
    scale_colour_manual(values = c("#E69F00", "#56B4E9")) +
    theme(legend.position = "bottom") +
    ggtitle("Recall estimates across L0 subsets") +
    xlab("Recall") +
    ylab("") +
    xlim(0.7, 1)
```

## System requirements

```{r}
devtools::session_info()
```

